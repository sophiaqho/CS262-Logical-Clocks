Hello - from /Users/sophiaho/.vscode/extensions/jaredly.reason-vscode-1.7.13/bin.native
Previous log location: /var/folders/x2/08rtd11n7zvgjpvymd2383mc0000gn/T/lsp.log
Sending notification {"jsonrpc": "2.0", "method": "client/registerCapability", "params": {"registrations": [{"id": "watching", "method": "workspace/didChangeWatchedFiles", "registerOptions": {"watchers": [{"globPattern": "**/bsconfig.json"}, {"globPattern": "**/.merlin"}]}}]}}
Sending response {"id": 0, "jsonrpc": "2.0", "result": {"capabilities": {"textDocumentSync": 1, "hoverProvider": true, "completionProvider": {"resolveProvider": true, "triggerCharacters": ["."]}, "signatureHelpProvider": {"triggerCharacters": ["("]}, "definitionProvider": true, "typeDefinitionProvider": true, "referencesProvider": true, "documentSymbolProvider": true, "codeActionProvider": true, "executeCommandProvider": {"commands": ["reason-language-server.add_to_interface_inner"]}, "codeLensProvider": {"resolveProvider": true}, "documentHighlightProvider": true, "documentRangeFormattingProvider": true, "documentFormattingProvider": true, "renameProvider": true}}}
Read message 
{"jsonrpc":"2.0","method":"initialized","params":{}}
Read message 
{"jsonrpc":"2.0","method":"workspace/didChangeConfiguration","params":{"settings":{"reason_language_server":{"location":"","build_system_override_by_root":{},"refmt":"","lispRefmt":"","mlfmt":"","format_width":80,"per_value_codelens":false,"dependencies_codelens":true,"opens_codelens":true,"show_module_path_on_hover":true,"reloadOnChange":false,"show_debug_errors":false,"autoRebuild":true}}}}
Read message 
{"jsonrpc":"2.0","method":"textDocument/didOpen","params":{"textDocument":{"uri":"file:///Users/sophiaho/CS51/2023TF/labs/lab10/src/lab10.cppo.ml","languageId":"ocaml","version":1,"text":"(*\n                             CS51 Lab 10\n           Time Complexity, Big-O, and Recurrence Equations\n *)\n#ifdef SOLN\n(*\n                               SOLUTION\n *)\n#endif\n\n(* Objective:\n\nThis lab is intended to practice concepts concerning efficiency and\ncomplexity, including:\n    Big O notation\n    Recurrence equations\n *)\n\n(* We open `CS51Utils` to provide access to the `Absbook` module, and\n   functions such as `Absbook.call_timed` and `Absbook.range`. You\n   installed the `CS51Utils` package at the beginning of the\n   course. You'll find the `Absbook` module source code in the file\n   `absbook.ml` in the CS51 utilities repository at\n   <https://github.com/cs51/utils>. *)\n\nopen CS51Utils ;;\n\n(*====================================================================\nPart 1: Empirical analysis of functions\n\nIn the reading, we empirically determined the efficiency of mergesort\nand insertion sort by timing these functions on the same inputs of\nvarious lengths. The ability to perform empirical analysis of programs\nwill often prove useful.\n\n    Throughout this lab you may find various functions in the\n    `Absbook` module to be helpful, as well as OCaml's `Random`\n    library module\n    <https://caml.inria.fr/pub/docs/manual-ocaml/libref/Random.html>.\n\n    In order to make use of the `Absbook` module from within `ocaml`\n    or `utop`, you may need to inform these REPLs of information about\n    the module's location. If you have trouble accessing `Absbook`\n    functions, try the commands in the following example:\n\n\t% ocaml\n\t\tOCaml version 4.11.1\n\n\t# #use \"topfind\" ;;\n\t...\n\t- : unit = ()\n\t# #require \"CS51Utils\" ;;\n\t...\n\t# open CS51Utils ;;\n\t# Absbook.call_timed ;;\n\t- : ?count:int -> ('a -> 'b) -> 'a -> 'b * float = <fun>\n\n......................................................................\nExercise 1: Write a function `random_list` that creates a list of a\nspecified length of random integers between 0 and 999. Hint: You may\nfind the `List.init` function to be helpful.\n....................................................................*)\n\n#ifndef SOLN\nlet random_list (length : int) : int list =\n  failwith \"random_list not implemented\" ;;\n#else\nlet random_list (length : int) : int list =\n  List.init length (fun _ -> Random.int 1000) ;;\n#endif\n\n(*....................................................................\nExercise 2: Write a function `time_sort` that, given an `int list ->\nint list` sorting function and a list of integers, returns a `float`\nindicating how long in seconds the sort takes. Hint: You may find the\n`Absbook.call_timed` function to be helpful.\n....................................................................*)\n\n#ifndef SOLN\nlet time_sort (sort : int list -> int list) (lst : int list) : float =\n  failwith \"time_sort not implemented\";;\n#else\nlet time_sort (sort : int list -> int list) (lst : int list) : float =\n  let _result, time = Absbook.call_timed sort lst in\n  time ;;\n#endif\n\n(* We've provided implementations of merge sort and insertion sort\nhere as modules satisfying the `SORT` signature so that you have some\nthings to time. *)\n   \nmodule type SORT =\n  sig\n    (* sort lt xs -- Return the list `xs` sorted in increasing\n       order by the \"less than\" function `lt`. *)\n    val sort : ('a -> 'a -> bool) -> 'a list -> 'a list\n  end ;;\n\nmodule InsertSort : SORT =\n  struct\n    let rec insert (lt : 'a -> 'a -> bool)\n                   (xs : 'a list)\n                   (x : 'a)\n                 : 'a list =\n      match xs with\n      | [] -> [x]\n      | hd :: tl -> if lt x hd then x :: xs\n                    else hd :: (insert lt tl x) ;;\n      \n    let rec sort (lt : 'a -> 'a -> bool)\n                 (xs : 'a list)\n               : 'list =\n      match xs with\n      | [] -> []\n      | hd :: tl -> insert lt (sort lt tl) hd ;;\n  end ;;\n\nmodule MergeSort : SORT = \n  struct\n    let rec split (xs : 'a list) =\n      match xs with\n      | [] -> [], []\n      | [x] -> [x], []\n      | first :: second :: rest -> let rest1, rest2 = split rest in\n                                   first :: rest1, second :: rest2\n        \n    let rec merge lt xs ys = \n      match xs, ys with \n      | [], _ -> ys\n      | _, [] -> xs\n      | x :: xst, y :: yst -> \n         if lt x y then x :: (merge lt xst ys)\n         else y :: (merge lt xs yst) \n      \n    let rec sort (lt : 'a -> 'a -> bool) (xs : 'a list) : 'a list = \n      match xs with \n      | []\n      | _ :: [] -> xs\n      | _ -> let first, second = split xs in\n             merge lt (sort lt first) (sort lt second) \n  end ;;\n\n(*....................................................................\nExercise 3: How many functions does the `InsertionSort` module\nprovide? How many functions does the `MergeSort` module\nprovide. Define the variables below accordingly (replacing the `-1`\nvalues).\n....................................................................*)\n\n#ifndef SOLN\nlet insertion_sort_provides : int = -1 ;;\nlet merge_sort_provides : int = -1 ;;\n#else\n(* Both modules provide a function\n\n       sort : ('a -> 'a -> bool) -> 'a list -> 'a list\n   \n   and *no other functions*, as specified by the SORT signature. In\n   particular, the functions insert, split, and merge are not\n   accessible outside the module. *)\n\nlet insertion_sort_provides : int = 1 ;;\nlet merge_sort_provides : int = 1 ;;\n#endif\n\n(*....................................................................\nExercise 4: Compare the time it takes for merge sort and insertion\nsort to run on lists of random ints of length 10 and 1000. We've\nincluded an implementation of merge and insertion sort below.\n....................................................................*)\n  \n#ifndef SOLN\n(* Fill in the table below:\n\n                |    List length 10    |  List length 1000\n                |    Time (seconds)    |  Time (seconds)\n------------------------------------------------------------\nInsertion Sort  |                      |\n------------------------------------------------------------\nMerge Sort      |                      |\n------------------------------------------------------------\n *)\n\n#else\n(* A first attempt to fill in the table may have included running the\n   following code:\n\n     time_sort (InsertSort.sort ( < )) (random_list 10);;\n     time_sort (InsertSort.sort ( < )) (random_list 1000) ;;\n     time_sort (MergeSort.sort  ( < )) (random_list 10) ;;\n     time_sort (MergeSort.sort  ( < )) (random_list 1000) ;;\n\n   However, this method of comparing the functions will not be\n   entirely accurate: merge sort and insertion sort are running on\n   different input lists. Though the lists are the same length, they\n   may be unsorted to a different degree. Just as when conducting\n   scientific experiments in a laboratory, we need to keep everything\n   but our subject of interest (in this case the sorting function)\n   constant to create a fair comparison.\n\n   Thus, our method of filling in the table looked as below:\n\n     let shortlist : int list = random_list 10 ;;\n     let longlist : int list = random_list 1000 ;;\n\n     time_sort (InsertSort.sort (<)) shortlist ;;\n     time_sort (InsertSort.sort (<)) longlist ;;\n     time_sort (MergeSort.sort  (<)) shortlist ;;\n     time_sort (MergeSort.sort  (<)) longlist ;;\n\n   Using this method, we generated the following times:\n\n                   |    List length 10    |  List length 1000\n                   |    Time (seconds)    |  Time (seconds)\n   ------------------------------------------------------------\n   Insertion Sort  |    0.00000215        |   0.0107\n   ------------------------------------------------------------\n   Merge Sort      |    0.00000405        |   0.000967\n   ------------------------------------------------------------\n\n   In summary, merge sort is a little slower on the short list but\n   much faster on the long list, consistent with its better\n   asymptotic complexity.\n\n   Generally when running experiments, it is good practice to run\n   more than one trial. We can do this for our timing as well to\n   increase our confidence in the time each algorithm takes. We may\n   start by writing a function that runs a number of trials and\n   averages the time of the result.\n\n   let run_sort_trials (num : int)\n                       (timer : (int list -> int list) -> int list -> float)\n                       (sort : (int list -> int list))\n                       (input : int list)\n                     : float =\n       let average (lst : float list) =\n           (List.fold_left ( +. ) 0. lst) \n           /. float_of_int (List.length lst) in\n       List.map (fun _ -> timer sort input)\n                (Absbook.range 1 num)\n       |> average ;;\n\n   We can then find the average of 50 trials for each list length.\n\n   run_sort_trials 50 time_sort (InsertSort.sort ( < )) shortlist ;;\n   run_sort_trials 50 time_sort (InsertSort.sort ( < )) longlist ;;\n   run_sort_trials 50 time_sort (MergeSort.sort ( < )) shortlist ;;\n   run_sort_trials 50 time_sort (MergeSort.sort ( < )) longlist ;;\n\n                   |    50 Trial Average  |  50 Trial Average\n                   |    List length 10    |  List length 1000\n                   |    Time (seconds)    |  Time (seconds)\n   ------------------------------------------------------------\n   Insertion Sort  |    0.00000178        |   0.00821\n   ------------------------------------------------------------\n   Merge Sort      |    0.00000198        |   0.000827\n   ------------------------------------------------------------\n *)\n\n#endif\n(*====================================================================\nPart 2: Big-O\n\n......................................................................\nExercise 5: In the reading for this lab, we saw that big-O notation is\na generic way of expressing the growth rate of a function. For each of\nthe functions defined below, state in which big-O class(es) the\nfunction belongs.\n\nTo allow us to check answers, we've defined an OCaml data type,\n`complexity`, with various commonly used big-O classes. The\nname-to-function mapping is set out below. We will use informal\nfunction notation in this lab. For more on informal versus formal\nnotation, please refer to the reading for today's lab.\n\n    Constant    -> O(1)\n    Logarithmic -> O(log(n))\n    Linear      -> O(n)\n    LogLinear   -> O(n log(n))\n    Quadratic   -> O(n^2)\n    Cubic       -> O(n^3)\n    Exponential -> O(2^n)\n\nBecause functions can be in more than one complexity class, the format\nof the solution to each exercise is a list of complexity classes. By\nway of example, we've done the first problem (Exercise 5a) for you.\n....................................................................*)\n\ntype complexity =\n    | Constant\n    | Logarithmic\n    | Linear\n    | LogLinear\n    | Quadratic\n    | Cubic\n    | Exponential ;;\n\n#ifndef SOLN\n(* f(x) = 5^x + x^3 *)\nlet exercise5a () : complexity list =\n  [Exponential] ;;\n\n(* f(x) = 0 *)\nlet exercise5b () : complexity list =\n  failwith \"exercise5b not implemented\" ;;\n\n(* f(x) = 3 x^2 + 2 x + 4 *)\nlet exercise5c () : complexity list=\n  failwith \"exercise5c not implemented\" ;;\n\n(* f(x) = (2 x - 3) log(x) + 100 x *)\nlet exercise5d () : complexity list =\n  failwith \"exercise5d not implemented\" ;;\n\n(* f(x) = x (x^2 + x) *)\nlet exercise5e () : complexity list =\n  failwith \"exercise5e not implemented\" ;;\n\n#else\n(* f(x) = 5^x + x^3 *)\nlet exercise5a () : complexity list =\n  [Exponential] ;;\n\n(* f(x) = 0 *)\nlet exercise5b () : complexity list =\n  [Constant; Logarithmic; Linear; LogLinear; Quadratic; Cubic; Exponential] ;;\n  \n(* f(x) = 3 x^2 + 2 x + 4  *)\nlet exercise5c () : complexity list =\n  [Quadratic; Cubic; Exponential] ;;\n\n(* f(x) = (2 x - 3) log(x) + 100 x *)\nlet exercise5d () : complexity list =\n  [LogLinear; Quadratic; Cubic; Exponential] ;;\n\n(* f(x) = x (x^2 + x) *)\nlet exercise5e () : complexity list =\n  [Cubic; Exponential] ;;\n\n(* Note: Often, we are most interested in the tightest big-O class a\n   function belongs to. When discussing functions such as f(x) = x^2,\n   you may hear someone say f is O(x^2). However, for f to be O(g), f\n   simply grows as slow or slower than g. Thus, we could also say that\n   for f(x) = x^2, f is O(2^x).  We will be explicit regarding\n   situations in which we would like you to determine a tight big-O\n   bound (that is, the slowest growing function class that f is a part\n   of) or a generic big-O bound (any function class f is a part of, as\n   we asked for in this problem). *)\n  \n#endif\n(* One advantage of big-O is that we can disregard constants in\nconsidering asymptotic performance of functions. We saw empirically\nthat on large inputs, merge sort worked faster than insertion\nsort. The ability to disregard constants tells us that merge sort will\neventually be faster than insertion sort, even if we add a constant\namount of time to merge sort's performance. \n\nLet's actually do this and test the results empirically!\n\nHere is a version of merge sort that inserts a small delay (.05\nseconds), to simulate a version of the function with the same\nasymptotic complexity but that is a constant amount slower. *)\n\nmodule DelayMergeSort : SORT =\n  struct\n    (* DelayMergeSort first sleeps for a predetermined period of time,\n       then runs our generic MergeSort sort.  This sleep will add a\n       constant amount of time to each run of DelayMergeSort.  *)\n    let sort (lt : 'a -> 'a -> bool)\n             (xs : 'a list)\n           : 'a list =\n      let () = Unix.sleepf 0.05 in\n      MergeSort.sort lt xs  ;;\n  end ;;\n\n(*....................................................................\nExercise 6: Additive constants\n\nFill in the table below.\n....................................................................*)\n\n#ifndef SOLN\n(*               |    List length 10    |  List length 1000\n                 |    Time (seconds)    |  Time (seconds)\n------------------------------------------------------------\nInsertion Sort   |                      |\n------------------------------------------------------------\nDelay Merge Sort |                      |\n------------------------------------------------------------*)\n\n#else\n(*               |    List length 10    |  List length 1000\n                 |    Time (seconds)    |  Time (seconds)\n------------------------------------------------------------\nInsertion Sort   |    0.00000215        |  0.0103\n------------------------------------------------------------\nDelay Merge Sort |    0.0516            |  0.0560\n------------------------------------------------------------*)\n\n#endif\n(* You likely found that InsertSort was faster than DelayMergeSort,\neven on a list of length 1000. Increase the length of the list being\nsorted by DelayMergeSort and InsertSort until DelayMergeSort runs\nfaster than InsertSort. Record the size of a list for which this is\ntrue below. *)\n   \n#ifndef SOLN\nlet exercise6 = 0    (* replace with the requested list size *)\n#else\nlet exercise6 = 10000 ;;\n#endif\n\n(* Big-O also allows us to disregard constant multiplicative\nfactors. In the next exercise, we work with a version of MergeSort\nthat sorts a given list twice rather than once.  However long\nMergeSort takes, DoubleMergeSort will thus take twice as long. *)\n\nmodule DoubleMergeSort : SORT =\n  struct\n    (* By sorting the list twice, we double the time MergeSort\n       takes *)\n    let sort (lt : 'a -> 'a -> bool)\n             (xs : 'a list)\n           : 'a list =\n      let _ = MergeSort.sort lt xs in\n      MergeSort.sort lt xs  ;;\n  end ;;\n  \n(*....................................................................\nExercise 7: Multiplicative constant factors\n\nComplete the same empirical analysis as above to compare the\nasymptotic behavior of InsertSort and DoubleMergeSort, and fill in the\ntable below.\n....................................................................*)\n\n#ifndef SOLN\n(*                |    List length 10    |  List length 1000\n                  |    Time (seconds)    |  Time (seconds)\n------------------------------------------------------------\nInsertion Sort    |                      |\n------------------------------------------------------------\nDouble Merge Sort |                      |\n------------------------------------------------------------*)\n#else\n(*                |    List length 10    |  List length 1000\n                  |    Time (seconds)    |  Time (seconds)\n------------------------------------------------------------\nInsertion Sort    |    0.00000191        |  0.00967\n------------------------------------------------------------\nDouble Merge Sort |    0.00000906        |  0.00174\n------------------------------------------------------------*)\n#endif\n\n(* Now record a list length for which you found DoubleMergeSort sorted\nfaster than InsertSort. *)\n   \n#ifndef SOLN\nlet exercise7 = 0    (* replace with the requested list size *)\n#else\nlet exercise7 = 1000 ;;\n#endif\n\n(* An additional nice property of big-O is the ability to disregard\nlower-order terms of a function. In the reading, we found that:\n\n    Time_mergesort(n) = c * n log n + d\n\nIn this exercise, we will work with a version of MergeSort that will\nadd an additional k * n term to the completion time of MergeSort. *)\n\nmodule ExtraTermMergeSort : SORT =\n  struct\n    let sort (lt : 'a -> 'a -> bool)\n             (xs : 'a list)\n           : 'a list =\n      (* We map the identity function over all of the elements of the\n         list and throw away the result, so as to waste time of O(n),\n         where n is the number of elements in the list *)\n      let _ = List.map (fun x -> x) xs in\n      MergeSort.sort lt xs;;\n  end ;;\n\n(*....................................................................\nExercise 8: Lower Order Terms\n\nComplete the same empirical analysis as above to compare the asymptotic\nbehavior of InsertSort and ExtraTermMergeSort, and fill in the table\nbelow.\n....................................................................*)\n\n#ifndef SOLN\n(*                    |    List length 10    |  List length 1000\n                      |    Time (seconds)    |  Time (seconds)\n-----------------------------------------------------------------\nInsertion Sort        |                      |\n-----------------------------------------------------------------\nExtra Term Merge Sort |                      |\n-----------------------------------------------------------------*)\n#else\n(*                    |    List length 10    |  List length 1000\n                      |    Time (seconds)    |  Time (seconds)\n-----------------------------------------------------------------\nInsertion Sort        |   0.00000286         |  0.0103\n-----------------------------------------------------------------\nExtra Term Merge Sort |   0.00000620         |  0.00105\n-----------------------------------------------------------------*)\n#endif\n\n(* Now record a list length for which ExtraTermMergeSort works faster\nthan InsertSort. *)\n#ifndef SOLN\nlet exercise8 = 0    (* replace with the requested list size *)\n#else\nlet exercise8 = 1000 ;;\n#endif\n\n(*....................................................................\nExercise 9: More big-O\n\nAs in Exercise 4, for each of the functions below, state to which\nbig-O classes the function belongs. See Exercise 4 for an example.\n\nAs a reminder, the big-O classes defined in our complexity ADT are\n\n    type complexity =\n        | Constant\n        | Logarithmic\n        | Linear\n        | LogLinear\n        | Quadratic\n        | Cubic\n        | Exponential ;;\n....................................................................*)\n\n#ifndef SOLN\n(* f(x) = 10000 *)\nlet exercise9a () : complexity list =\n  failwith \"exercise9a not implemented\" ;;\n  \n(* f(x) = 50x^100 + x^2 *)\nlet exercise9b () : complexity list =\n  failwith \"exercise9b not implemented\" ;;\n\n(* f(x) = 30xlog(x) + 50x + 70 *)\n\nlet exercise9c () : complexity list =\n  failwith \"exercise9c not implemented\" ;;\n\n(* f(x) = 30x^2 * log(x) *)\nlet exercise9d () : complexity list =\n  failwith \"exercise9d not implemented\" ;;\n\n(* f(x) = x + 60log(x) *)\nlet exercise9e () : complexity list =\n  failwith \"exercise9e not implemented\" ;;\n\n#else\n(* f(x) = 10000 *)\nlet exercise9a () : complexity list =\n  [Constant; Logarithmic; Linear; LogLinear; Quadratic; Cubic; Exponential] ;;\n\n(* f(x) = 50x^100 + x^2 *)\nlet exercise9b () : complexity list =\n  [Exponential] ;;\n\n(* f(x) = 30xlog(x) + 50x + 70 *)\nlet exercise9c () : complexity list =\n  [LogLinear; Quadratic; Cubic; Exponential] ;;\n\n(* f(x) = 30x^2 * log(x) *)\nlet exercise9d () : complexity list =\n  [Cubic; Exponential] ;;\n(* Note: This is a bit tricky. Because we are multiplying 30x^2 and\n   log(x), we can't simply disregard the log(x), as we could do if\n   adding it. 30x^2 * log(x) will not be quadratic, as the log(x) will\n   grow faster than any constant we multiply x^2 by. However, log(x)\n   grows slower than x, so we know x^2 * log(x) will grow more slowly\n   than x^2 * x, so f must grow more slowly than x^3, making this\n   function O(x^3) and O(2^x) *)\n\n(* f(x) = x + 60log(x) *)\nlet exercise9e () : complexity list =\n  [Linear; LogLinear; Quadratic; Cubic; Exponential] ;;\n  \n#endif\n(*====================================================================\nPart 3: Recurrence Equations\n\nOnce we know the complexity of a function, we can use big-O notation\nto compare that function's asymptotic performance with other\nfunctions. However, a function's complexity may not be immediately\nobvious. Recurrence equations provide an analytical way to determine\nthe complexity of a function.\n\nRecurrence equations generally consider two cases:\n\n1. A base case\n2. A recursive case\n\nOnce you have formulated the recursive case, you can use the method of\n\"unfolding\" described in the reading to determine the time complexity\nof the functions.\n\nIn each of the exercises below, we present a function in OCaml. Your\ntask is to define the recurrence equations for that function, and then\nto solve the recurrence equations via unfolding, to generate a\nclosed-form equation and form a conclusion about the time complexity\nof the function in big-O notation.\n\nTo facilitate automated testing of the recurrence equations you come\nup with, we ask you to present them in the form of an OCaml\nfunction. (We provide an example below.)  We encourage you to first\ncomplete the problem on paper, with the notation from the chapter and\nusing the unfolding method, and then transfer your solutions\nhere. When finding the time complexity, we would like you to use the\ntightest possible big-O class.\n\nMany of the recurrences have various constants. We have defined a\nglobal variable, `k`, for you to use for *all* of the constants in your\nOCaml formulation of the recurrence equations. Again, the example\nbelow should clarify. *)\n\nlet k = 5;;\n\n(* An example of the method we would like you to use for presenting\nyour recurrence equations and complexity is provided below, based on\nthe `insert` function from the reading. *)\n\n(*....................................................................\n                        RECURRENCE EXAMPLE\n....................................................................*)\nlet rec insert xs x =\n    match xs with\n    | [] -> [x]\n    | h :: t -> if x > h then h :: (insert t x)\n                  else x :: xs ;;\n(*....................................................................\nComplete the recurrence equations and time complexity of this\nfunction:\n....................................................................*)\n\n(*\nlet time_insert (n : int) : int =\n    failwith \"time_insert not yet implemented\" ;;\n\nlet insert_complexity () : complexity =\n    failwith \"insert_complexity not yet implemented\" ;;\n*)\n\n(*....................................................................\n                            SOLUTION\n\nWe saw in the reading that the `insert` function has the following\nrecurrence equations:\n\nT_insert(0) = c\nT_insert(n) = max(k_1 + T_insert(n-1), k_2) â‰¤ k_1 + T_insert(n-1) + k_2\n            = k + T_insert(n-1)\n\nWe express these equations with the following Ocaml function. Rather\nthan write two equations, as you might on paper, we write the base\ncase and recursive case as branches of an if/then/else\nstatement. Although the recurrence equations have two constants (c and\nk), we use the single OCaml variable `k` to play both of those roles.\nPlease follow that format in all of the following exercises.\n....................................................................*)\n  \nlet rec time_insert (n : int) : int =\n  if n = 0 then k\n  else k + time_insert (n - 1) ;;\n\n(* (Note that this function will run forever on inputs below 0. We\nwould normally expect you to handle invalid inputs. However, for the\npurpose of practicing recurrence equations, you may assume inputs will\nalways be positive or nonnegative as the equations require.)\n\nFor the time complexity, we use a value from the complexity type to\nexpress the tightest big-O bound for this linear function. *)\n\nlet insert_complexity () : complexity =\n  Linear ;;\n\n(* Now it's time for you to construct and solve some recurrence\nequations, and add them to the lab using the method above.\n\n                            END OF EXAMPLE\n *)\n  \n(*....................................................................\nExercise 10: Sum recurrence equations\n\nFormulate the recurrence equations and determine the time complexity\nof the `sum` function, defined below.\n....................................................................*)\n\nlet rec sum (x : int list) : int =\n  match x with\n  | [] -> 0\n  | h :: t -> h + sum t;;\n\n#ifndef SOLN\n(* Describe the time complexity recurrence equations for `sum` as an\nOCaml function of `n`, the length of the list. *)\nlet time_sum (n : int) : int =\n  failwith \"time_sum not yet implemented\" ;;\n\n(* What is its complexity? *) \nlet sum_complexity () : complexity =\n  failwith \"sum_complexity not yet implemented\" ;;\n  \n#else\n(* Describe the time complexity recurrence equations for `sum` as an\nOCaml function of `n`, the length of the list. *)\nlet rec time_sum (n : int) : int =\n  if n = 0 then k\n  else k + time_sum (n - 1) ;;\n\n(* What is its complexity? *) \nlet sum_complexity () : complexity =\n  Linear ;;\n  \n#endif\n(*....................................................................\nExercise 11: Divider Recurrence Equations\n\nFormulate the recurrence equations and determine the time complexity\nof `divider`, defined below, in terms of the value of its argument\n`x`.\n....................................................................*)\n\nlet rec divider (x : int) : int =\n  if x < 0 then\n    raise (Invalid_argument \"only positive numbers accepted\")\n  else if x <= 1 then 0\n  else 1 + divider (x / 2) ;;\n  \n#ifndef SOLN\nlet time_divider (n : int) : int =\n  failwith \"time_sum not yet implemented\" ;;\n\nlet divider_complexity () : complexity =\n  failwith \"time_complexity not yet implemented\" ;;\n\n#else\nlet rec time_divider (n : int) : int =\n  if n = 0 || n = 1 then k\n  else k + time_divider (n / 2) ;;\n\n(* Note: Initially it may seem that `divider`'s input \"size\" can never\n   change: The input is an int, and only ever one int. However,\n   divider will repeat a given number of times depending on the value\n   of the argument. Thus the size of the input in divider is actually\n   the value of the integer input, rather than the length of a list\n   input as we had previously seen.\n   \n   We complete the unfolding process as below:\n     T_div(n) = k + T_div(n / 2)\n              = k + k + T_div(n / 4)\n              = k + k + K + T_div(n / 8)\n              = k + k + k + ... + T_div(0)\n              = k + k + k + ... + q\n\n   How many k's will we have in the end?  We will have as many k's as\n   times that we divide n by 2 before hitting 0. This is approximately\n   log base 2 of n.\n\n     Thus, T_div(n) = k*log(n) + q\n                    = O(log(n))\n *)\n  \nlet divider_complexity () : complexity =\n  Logarithmic;;\n\n#endif\n(*....................................................................\nExercise 12: Find_min recurrence equations\n\nFormulate the recurrence equations and determine the time complexity\nof `find_min` as defined below. The `find_min` function contains a\nhelper function, `split`. First find the recurrence equations and time\ncomplexity of `split`, as you may find this helpful in determining the\ntime complexity of `find_min`.\n....................................................................*)\n\nlet rec find_min (xs : int list) : int =\n  \n  let rec split (xs : 'a list) =\n    match xs with\n    | [] -> [], []\n    | [x] -> [x], []\n    | first :: second :: rest -> let rest1, rest2 = split rest in\n                                 first :: rest1, second :: rest2 in\n  \n  match xs with\n  | [] -> raise (Invalid_argument \"Empty List\")\n  | [x] -> x\n  | _ -> let xs1, xs2 = split xs in\n         min (find_min xs1) (find_min xs2) ;;\n\n#ifndef SOLN\nlet time_split (n : int) : int =\n  failwith \"time_split not yet implemented\" ;;\n\nlet split_complexity () : complexity =\n  failwith \"split_complexity not yet implemented\" ;;\n\nlet time_find_min (n : int) : int =\n  failwith \"time_find_min not yet implemented\" ;;\n\nlet find_min_complexity () : complexity =\n  failwith \"find_min_complexity not yet implemented\" ;;\n\n#else\nlet rec time_split (n : int) : int =\n  if n = 0 || n = 1 then k\n  else k + time_split (n - 2) ;;\n\n(* Split considers 2 elements at a time, thus we subtract 2 in the\n   recursive case. We can unfold as below:\n\n   T_split(0) = T_split(1) = q\n   T_split(n) = k + T_split(n - 2)\n              = k + k + T_split(n - 4)\n              = k + k + ... + T(0)\n              = k + k + .... + q\n\n   How many k's will we have? Not exactly n, as we subtracted\n   2 each unfold. Instead, we will have n/2. Our closed\n   form solution is thus:\n\n   T_split(n) = k * (n / 2) + q\n\n   However, when discussing in big-O, this division by\n   two may be disregarded, and we have that T_split is O(n).\n *)\n\nlet split_complexity () : complexity =\n  Linear ;;\n\nlet rec time_find_min (n : int) : int =\n  if n = 0 || n = 1 then k\n  else k + (time_split n) + 2 * time_find_min (n / 2) ;;\n  \n(* When unfolding `find_min`, you may have recognized the \"Divide and\n   Conquer\" pattern discussed in the reading.  You also had to know\n   the time complexity of `split` to determine the time complexity of\n   find min. Often, it can be useful to consider each helper\n   function's complexity separately. You can then use the derived\n   closed form solutions when calculating the time complexity of the\n   larger function.\n\n   T_fm(0) = T_fm(1) = c\n   T_fm(n) = k + T_split(n) + 2T_fm(n/2)    <-   We can immediately substitute our\n   T_fm(n) = k + k * (n / 2) + q + 2T_fm(n/2)    closed form solution for T_split\n   T_fm(n) = k + k * (n / 2) + q + k + 2T_split(n/2) + 4T_fm(n/4)\n   T_fm(n) = k + k * (n / 2) + q + k + 2k * (n / 4) + 2q + 4T_fm(n/4)\n   T_fm(n) = k + k * (n / 2) + q + k + k * (n / 2) + 2q + 4T_fm(n/4)\n   ....\n\n   We will end up unfolding log(n) times total. Each time we unfold we\n   add a constant related to the time to match and call functions, and\n   terms relating to the splitting time. In total, our constant k\n   will be summed log(n) times, giving us a k * log(n) term in our\n   closed form solution.\n\n   Splitting adds two terms each time, one constant (q), and one\n   linear in the size of the list being split (k * n / 2). The linear\n   term stays a consistent k * n / 2. Though we make more splits, the\n   size of the list halves, and these forces cancel each other\n   out. (Ignoring for a moment the constant in the split closed\n   form solution, 2T_split(n/2) becomes 2(k * n / 4) = k * n / 2). As\n   we unfold log(n) times, adding a k * n / 2 term each time, we will\n   have a term of log(n) * k * n / 2 = k * nlog(n) / 2 in our closed\n   form.\n\n   We can now return to the constant in the closed form solution of\n   T_split.  How does this constant affect the closed form\n   solution. Let's look only at what happens to this constant in each\n   unfold:\n\n   T_fm(n) = k + k * (n / 2) + q + k + k * (n / 2) + 2q + 4T_fm(n/4)\n   T_fm(n) = ..... + q + .... + 2q + 4T_fm(n/4)\n   T_fm(n) = ..... + q + .... + 2q + .... + 4q + 8T_fm(n/8)\n\n   Each time we unfold, we double the number of q's we add.\n   Thus, at the k'th unfold, we add 2^k * q to our equation.\n   In the base case, we are at the log(n)th unfold. Though we have\n   been vague thus far, we assume a log base 2 for simplicity of\n   computation. Thus at the k'th unfold we add 2^(log(n)) * q.\n   This simplifies to n * q. As each term added is double the\n   term before, the total amount of steps added from this\n   component is less than 2 * n * q. Thus, this constant adds a linear\n   term to our closed form solution.\n\n   The last component of our closed form solution is the constant, c,\n   that encompassess the time the two base cases take.\n\n   Gathering all our terms, we have:\n   T_fm(n) = k * log(n) + (k / 2) * nlog(n) + 2 * q * n + c\n\n   To find the closest big O class, we need only look at the largest\n   term. This term is (k / 2) * n log(n). We can drop constant factors,\n   finding that find_min is O(n log(n))\n *)\n\nlet find_min_complexity () : complexity =\n    LogLinear ;;\n\n#endif\n(*====================================================================\nPart 4: Tradeoffs\n\nConsider the three implementations of multiplication below:\n *)\n\nlet sign_product (x : int) (y : int) : int =\n    let sign (x : int) : int =\n        if x >= 0 then 1 else ~-1 in\n    (sign x) * (sign y);;\n\n(* 1. Repeated addition simply adds `x` to itself `y` times. To\nmultiply two n-digit numbers together using this algorithm takes time\nO(n 10^n). It is thus tremendously inefficient. *)\n\nlet mult_repeated_addition (x : int) (y : int) : int =\n  let rec helper (y : int) (sum : int) =\n    if y < 0 then raise (Invalid_argument \"negative input\")\n    else if y = 0 then 0\n    else helper (y - 1) (sum + (abs x)) in\n  helper (abs y) 0 * (sign_product x y) ;;\n  \n(* 2. The gradeschool multiplication algorithm is the algorithm one\nwould use when doing multiplication of large numbers on paper. To\nmultiply two n-digit numbers together using this algorithm takes time\nO(n^2) *)\n  \nlet mult_grade_school (x : int) (y : int) : int =\n  let product_sign = sign_product x y in\n  let x = abs x in\n  let y = abs y in\n  let base = 10 in\n  let single_digit_mult (x : int) (y : int) =\n    let rec helper x carry placevalue =\n      if x = 0 then carry * placevalue\n      else let prod = y * (x mod base) + carry in\n           let new_carry, place = (prod / base, prod mod base) in\n           place * placevalue +\n             helper  (x / base) new_carry (placevalue * base)\n    in if y < 0 || y > 9 then\n         raise (Invalid_argument \"multiple digit or neg. y\")\n       else helper x 0 1 in\n  let rec iterate_y y placevalue =\n    if y = 0 then 0\n    else placevalue * single_digit_mult x (y mod 10)\n         + iterate_y (y / 10) (placevalue * base) in\n  product_sign * iterate_y y 1 ;;\n\n(* 3. The Karatsuba algorithm is a multiplication algorithm that\nutilizes a divide-and-conquer approach. It was divised in 1960 by\n23-year-old student Anatoly Karatsuba after his Professor Andrey\nKolmogorov conjectured that the fastest possible multiplication\nalgorithm would be lower bounded (that is, no faster than) O(n^2).\nKaratsuba's algorithm disproved that conjecture. To multiply two\nn-digit numbers, Karatsuba's algorithm runs in O(n^(log_2 3)), that\nis, n to the power of log base 2 of 3, which is about n^1.4.\n\n*You do not need to understand the algorithm for this class*, but can\nfind out more on Wikipedia if interested:\nhttps://en.wikipedia.org/wiki/Karatsuba_algorithm *)\n  \nlet mult_karatsuba (x : int) (y : int) : int =\n  let tens_power (power : int) : int =\n    let num_string = \"1\" ^ (String.make power '0') in\n    int_of_string num_string in\n  let rec karatsuba x y =\n    if x < 10 || y < 10 then  x * y\n    else let num_digits_x = String.length (string_of_int x) in\n         let num_digits_y = String.length (string_of_int y)  in\n         let min_digits = min num_digits_x num_digits_y in\n         let half_place = tens_power (min_digits / 2) in\n         let highx, lowx = (x / half_place, x mod half_place) in\n         let highy, lowy = (y / half_place, y mod half_place) in\n         let a = karatsuba lowx lowy in\n         let b = karatsuba (lowx + highx) (lowy + highy) in\n         let c = karatsuba highx highy in\n         c * half_place * half_place\n         + half_place * (b - c - a) + a in\n  (sign_product x y) * karatsuba (abs x) (abs y) ;;\n\n(*....................................................................\nExercise 13: Write a function `time_multiply` that, given a\nmultiplication function and two integers, times how long in seconds\nthe algorithm takes to multiply the integers.\n....................................................................*)\n  \n#ifndef SOLN\nlet time_multiply (mult : int -> int -> int)\n                  (x : int)\n                  (y : int)\n                : float =\n  failwith \"time_multiply not yet implemented\";;\n#else\nlet time_multiply (mult : int -> int -> int)\n                  (x : int)\n                  (y : int)\n                : float =\n  let _result, time = Absbook.call_timed\n                        (fun (x, y) -> mult x y)\n                        (x, y) in\n  time ;;\n#endif\n\n(*....................................................................\nExercise 14: Fill in the table below:\n....................................................................*)\n   \n#ifndef SOLN\n(*                     |    15 * 50           |  1241342345 *\n                       |                      |  3237461243\n                       |    Time (seconds)    |  Time (seconds)\n-----------------------------------------------------------------\nRepeated Addition      |                      |\n-----------------------------------------------------------------\nGrade School Algorithm |                      |\n-----------------------------------------------------------------\nKaratsuba              |                      |\n-----------------------------------------------------------------\nOCaml Native ( * )     |                      |\n-----------------------------------------------------------------\n *)\n        \n#else\n(* Here's what we found. Of course, your results might vary a bit.\n\n                       |    15 * 50           |  1241342345 *\n                       |                      |  3237461243\n                       |    Time (seconds)    |  Time (seconds)\n-----------------------------------------------------------------\nRepeated Addition      |     0.00000286       |  83.5\n-----------------------------------------------------------------\nGrade School Algorithm |     0.00000310       |  0.0000129\n-----------------------------------------------------------------\nKaratsuba              |     0.00000787       |  0.0000281\n-----------------------------------------------------------------\nOCaml Native ( * )     |     0.00000119       |  ~0\n-----------------------------------------------------------------\n   *)\n  \n#endif\n(* Questions to consider:\n\n      1. Which algorithm above was easiest to understand?\n      2. Which algorithm was likely easiest to code?\n      3. Which was fastest on small numbers?\n      4. Which was fastest on large numbers?\n      5. What size integers do you typically multiply?\n      6. Which algorithm, then, would you consider the best?\n *)\n"}}}
Found a `dune` file at /Users/sophiaho/CS51/2023TF/labs/lab10/src
]] Making a new jbuilder package at /Users/sophiaho/CS51/2023TF/labs/lab10/src
=== Project root: /Users/sophiaho/CS51/2023TF/labs/lab10
Detected `opam` dependency manager for local use
Sending notification {"jsonrpc": "2.0", "method": "window/showMessage", "params": {"type": 1, "message": "Unable to read /Users/sophiaho/CS51/2023TF/labs/lab10/src/.merlin"}}
Read message 
{"jsonrpc":"2.0","id":1,"method":"textDocument/documentSymbol","params":{"textDocument":{"uri":"file:///Users/sophiaho/CS51/2023TF/labs/lab10/src/lab10.cppo.ml"}}}
[server] Got a method textDocument/documentSymbol
[server] processing took 0.0121593475342ms
Found a `dune` file at /Users/sophiaho/CS51/2023TF/labs/lab10/src
]] Making a new jbuilder package at /Users/sophiaho/CS51/2023TF/labs/lab10/src
=== Project root: /Users/sophiaho/CS51/2023TF/labs/lab10
Detected `opam` dependency manager for local use
Sending response {"id": 1, "jsonrpc": "2.0", "error": {"code": -32603, "message": "Unable to read /Users/sophiaho/CS51/2023TF/labs/lab10/src/.merlin"}}
Found a `dune` file at /Users/sophiaho/CS51/2023TF/labs/lab10/src
]] Making a new jbuilder package at /Users/sophiaho/CS51/2023TF/labs/lab10/src
=== Project root: /Users/sophiaho/CS51/2023TF/labs/lab10
Detected `opam` dependency manager for local use
Read message 
{"jsonrpc":"2.0","id":2,"method":"textDocument/codeAction","params":{"textDocument":{"uri":"file:///Users/sophiaho/CS51/2023TF/labs/lab10/src/lab10.cppo.ml"},"range":{"start":{"line":0,"character":0},"end":{"line":0,"character":0}},"context":{"diagnostics":[]}}}
[server] Got a method textDocument/codeAction
[server] processing took 0.0240802764893ms
Found a `dune` file at /Users/sophiaho/CS51/2023TF/labs/lab10/src
]] Making a new jbuilder package at /Users/sophiaho/CS51/2023TF/labs/lab10/src
=== Project root: /Users/sophiaho/CS51/2023TF/labs/lab10
Detected `opam` dependency manager for local use
Sending response {"id": 2, "jsonrpc": "2.0", "error": {"code": -32603, "message": "Unable to read /Users/sophiaho/CS51/2023TF/labs/lab10/src/.merlin"}}
Read message 
{"jsonrpc":"2.0","id":3,"method":"textDocument/codeLens","params":{"textDocument":{"uri":"file:///Users/sophiaho/CS51/2023TF/labs/lab10/src/lab10.cppo.ml"}}}
[server] Got a method textDocument/codeLens
[server] processing took 0.0131130218506ms
Found a `dune` file at /Users/sophiaho/CS51/2023TF/labs/lab10/src
]] Making a new jbuilder package at /Users/sophiaho/CS51/2023TF/labs/lab10/src
=== Project root: /Users/sophiaho/CS51/2023TF/labs/lab10
Detected `opam` dependency manager for local use
Sending response {"id": 3, "jsonrpc": "2.0", "result": [{"range": {"start": {"line": 0, "character": 0}, "end": {"line": 0, "character": 0}}, "command": {"title": "Unable to load compilation data: Unable to read /Users/sophiaho/CS51/2023TF/labs/lab10/src/.merlin", "command": ""}}]}
Read message 
{"jsonrpc":"2.0","method":"$/cancelRequest","params":{"id":3}}
Read message 
{"jsonrpc":"2.0","id":4,"method":"textDocument/codeLens","params":{"textDocument":{"uri":"file:///Users/sophiaho/CS51/2023TF/labs/lab10/src/lab10.cppo.ml"}}}
[server] Got a method textDocument/codeLens
[server] processing took 0.0100135803223ms
Found a `dune` file at /Users/sophiaho/CS51/2023TF/labs/lab10/src
]] Making a new jbuilder package at /Users/sophiaho/CS51/2023TF/labs/lab10/src
=== Project root: /Users/sophiaho/CS51/2023TF/labs/lab10
Detected `opam` dependency manager for local use
Sending response {"id": 4, "jsonrpc": "2.0", "result": [{"range": {"start": {"line": 0, "character": 0}, "end": {"line": 0, "character": 0}}, "command": {"title": "Unable to load compilation data: Unable to read /Users/sophiaho/CS51/2023TF/labs/lab10/src/.merlin", "command": ""}}]}
Read message 
{"jsonrpc":"2.0","method":"$/cancelRequest","params":{"id":4}}
Read message 
{"jsonrpc":"2.0","method":"textDocument/didClose","params":{"textDocument":{"uri":"file:///Users/sophiaho/CS51/2023TF/labs/lab10/src/lab10.cppo.ml"}}}
Read message 
{"jsonrpc":"2.0","id":5,"method":"shutdown","params":null}
Sending response {"id": 5, "jsonrpc": "2.0", "result": null}
Read message 
{"jsonrpc":"2.0","method":"exit","params":null}
Got exit! Terminating loop
Finished
